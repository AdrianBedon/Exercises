{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras.datasets import mnist\n",
    "from keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def relu(x):\n",
    "    return np.maximum(0,x)\n",
    "\n",
    "def relu_prime(x):\n",
    "    return np.where(x > 0, 1, 0)\n",
    "    \n",
    "def mse(y_true, y_pred):\n",
    "    return np.mean(np.power(y_true-y_pred, 2));\n",
    "\n",
    "def mse_prime(y_true, y_pred):\n",
    "    return 2*(y_pred-y_true)/y_true.size;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Abstract Class Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Layer:\n",
    "    def __init__(self):\n",
    "        self.input = None\n",
    "        self.output = None\n",
    "\n",
    "    def forward_propagation(self, input):\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def backward_propagation(self, output_error, learning_rate):\n",
    "        raise NotImplementedError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DropoutLayer:\n",
    "    def __init__(self, p):\n",
    "        self.p = p\n",
    "        self.mask = None\n",
    "\n",
    "    def forward_propagation(self, input_data, training=True):\n",
    "        if training:\n",
    "            self.mask = np.random.binomial(1, 1 - self.p, size=input_data.shape)\n",
    "            return input_data * self.mask\n",
    "        else:\n",
    "            return input_data * (1 - self.p)\n",
    "\n",
    "    def backward_propagation(self, output_error, learning_rate):\n",
    "        return output_error * self.mask"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Fully-connected Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FCLayer(Layer):\n",
    "    def __init__(self, input_size, output_size):\n",
    "        self.weights = np.random.rand(input_size, output_size) - 0.5\n",
    "        self.bias = np.random.rand(1, output_size) - 0.5\n",
    "\n",
    "    def forward_propagation(self, input_data):\n",
    "        self.input = input_data\n",
    "        self.output = np.dot(self.input, self.weights) + self.bias\n",
    "        return self.output\n",
    "\n",
    "    def backward_propagation(self, output_error, learning_rate):\n",
    "        input_error = np.dot(output_error, self.weights.T)\n",
    "        weights_error = np.dot(self.input.T, output_error)\n",
    "        self.weights -= learning_rate * weights_error\n",
    "        self.bias -= learning_rate * output_error\n",
    "        return input_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Activation Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ActivationLayer(Layer):\n",
    "    def __init__(self, activation, activation_prime):\n",
    "        self.activation = activation\n",
    "        self.activation_prime = activation_prime\n",
    "\n",
    "    def forward_propagation(self, input_data):\n",
    "        self.input = input_data\n",
    "        self.output = self.activation(self.input)\n",
    "        return self.output\n",
    "\n",
    "    def backward_propagation(self, output_error, learning_rate):\n",
    "        return self.activation_prime(self.input) * output_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Network Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Network:\n",
    "    def __init__(self):\n",
    "        self.layers = []\n",
    "        self.loss = None\n",
    "        self.loss_prime = None\n",
    "\n",
    "    def add(self, layer):\n",
    "        self.layers.append(layer)\n",
    "\n",
    "    def use(self, loss, loss_prime):\n",
    "        self.loss = loss\n",
    "        self.loss_prime = loss_prime\n",
    "\n",
    "    def predict(self, input_data):\n",
    "        samples = len(input_data)\n",
    "        result = []\n",
    "        for i in range(samples):\n",
    "            output = input_data[i]\n",
    "            for layer in self.layers:\n",
    "                output = layer.forward_propagation(output)\n",
    "            result.append(output)\n",
    "        return result\n",
    "\n",
    "    def fit(self, x_train, y_train, epochs, learning_rate):\n",
    "        samples = len(x_train)\n",
    "        for i in range(epochs):\n",
    "            err = 0\n",
    "            for j in range(samples):\n",
    "                output = x_train[j]\n",
    "                for layer in self.layers:\n",
    "                    output = layer.forward_propagation(output)\n",
    "                err += self.loss(y_train[j], output)\n",
    "                error = self.loss_prime(y_train[j], output)\n",
    "                for layer in reversed(self.layers):\n",
    "                    error = layer.backward_propagation(error, learning_rate)\n",
    "            err /= samples\n",
    "            print('epoch %d/%d   error=%f' % (i+1, epochs, err))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1/500   error=0.488223\n",
      "epoch 2/500   error=0.378883\n",
      "epoch 3/500   error=0.362354\n",
      "epoch 4/500   error=0.300484\n",
      "epoch 5/500   error=0.277071\n",
      "epoch 6/500   error=0.235262\n",
      "epoch 7/500   error=0.304098\n",
      "epoch 8/500   error=0.236013\n",
      "epoch 9/500   error=0.230800\n",
      "epoch 10/500   error=0.214444\n",
      "epoch 11/500   error=0.211600\n",
      "epoch 12/500   error=0.202078\n",
      "epoch 13/500   error=0.278674\n",
      "epoch 14/500   error=0.181075\n",
      "epoch 15/500   error=0.189528\n",
      "epoch 16/500   error=0.266392\n",
      "epoch 17/500   error=0.299207\n",
      "epoch 18/500   error=0.329030\n",
      "epoch 19/500   error=0.246769\n",
      "epoch 20/500   error=0.152339\n",
      "epoch 21/500   error=0.134549\n",
      "epoch 22/500   error=0.121664\n",
      "epoch 23/500   error=0.101764\n",
      "epoch 24/500   error=0.169460\n",
      "epoch 25/500   error=0.202608\n",
      "epoch 26/500   error=0.073945\n",
      "epoch 27/500   error=0.062917\n",
      "epoch 28/500   error=0.119483\n",
      "epoch 29/500   error=0.028680\n",
      "epoch 30/500   error=0.022093\n",
      "epoch 31/500   error=0.089191\n",
      "epoch 32/500   error=0.007331\n",
      "epoch 33/500   error=0.002451\n",
      "epoch 34/500   error=0.251348\n",
      "epoch 35/500   error=0.086775\n",
      "epoch 36/500   error=0.004340\n",
      "epoch 37/500   error=0.002049\n",
      "epoch 38/500   error=0.084771\n",
      "epoch 39/500   error=0.001457\n",
      "epoch 40/500   error=0.084302\n",
      "epoch 41/500   error=0.084078\n",
      "epoch 42/500   error=0.083504\n",
      "epoch 43/500   error=0.000554\n",
      "epoch 44/500   error=0.000446\n",
      "epoch 45/500   error=0.000067\n",
      "epoch 46/500   error=0.083644\n",
      "epoch 47/500   error=0.083579\n",
      "epoch 48/500   error=0.166847\n",
      "epoch 49/500   error=0.000246\n",
      "epoch 50/500   error=0.000146\n",
      "epoch 51/500   error=0.000115\n",
      "epoch 52/500   error=0.000011\n",
      "epoch 53/500   error=0.166748\n",
      "epoch 54/500   error=0.166732\n",
      "epoch 55/500   error=0.000083\n",
      "epoch 56/500   error=0.000045\n",
      "epoch 57/500   error=0.083363\n",
      "epoch 58/500   error=0.083365\n",
      "epoch 59/500   error=0.083354\n",
      "epoch 60/500   error=0.166672\n",
      "epoch 61/500   error=0.083350\n",
      "epoch 62/500   error=0.083335\n",
      "epoch 63/500   error=0.083346\n",
      "epoch 64/500   error=0.000010\n",
      "epoch 65/500   error=0.083341\n",
      "epoch 66/500   error=0.000007\n",
      "epoch 67/500   error=0.166672\n",
      "epoch 68/500   error=0.083338\n",
      "epoch 69/500   error=0.083338\n",
      "epoch 70/500   error=0.083336\n",
      "epoch 71/500   error=0.000003\n",
      "epoch 72/500   error=0.166668\n",
      "epoch 73/500   error=0.083334\n",
      "epoch 74/500   error=0.000001\n",
      "epoch 75/500   error=0.083335\n",
      "epoch 76/500   error=0.000001\n",
      "epoch 77/500   error=0.000001\n",
      "epoch 78/500   error=0.000001\n",
      "epoch 79/500   error=0.083334\n",
      "epoch 80/500   error=0.000001\n",
      "epoch 81/500   error=0.000000\n",
      "epoch 82/500   error=0.000000\n",
      "epoch 83/500   error=0.083334\n",
      "epoch 84/500   error=0.083333\n",
      "epoch 85/500   error=0.000000\n",
      "epoch 86/500   error=0.000000\n",
      "epoch 87/500   error=0.000000\n",
      "epoch 88/500   error=0.083333\n",
      "epoch 89/500   error=0.000000\n",
      "epoch 90/500   error=0.000000\n",
      "epoch 91/500   error=0.000000\n",
      "epoch 92/500   error=0.000000\n",
      "epoch 93/500   error=0.000000\n",
      "epoch 94/500   error=0.083333\n",
      "epoch 95/500   error=0.083333\n",
      "epoch 96/500   error=0.000000\n",
      "epoch 97/500   error=0.000000\n",
      "epoch 98/500   error=0.083333\n",
      "epoch 99/500   error=0.000000\n",
      "epoch 100/500   error=0.000000\n",
      "epoch 101/500   error=0.000000\n",
      "epoch 102/500   error=0.000000\n",
      "epoch 103/500   error=0.000000\n",
      "epoch 104/500   error=0.166667\n",
      "epoch 105/500   error=0.166667\n",
      "epoch 106/500   error=0.000000\n",
      "epoch 107/500   error=0.000000\n",
      "epoch 108/500   error=0.166667\n",
      "epoch 109/500   error=0.000000\n",
      "epoch 110/500   error=0.083333\n",
      "epoch 111/500   error=0.000000\n",
      "epoch 112/500   error=0.166667\n",
      "epoch 113/500   error=0.083333\n",
      "epoch 114/500   error=0.083333\n",
      "epoch 115/500   error=0.000000\n",
      "epoch 116/500   error=0.083333\n",
      "epoch 117/500   error=0.000000\n",
      "epoch 118/500   error=0.000000\n",
      "epoch 119/500   error=0.083333\n",
      "epoch 120/500   error=0.000000\n",
      "epoch 121/500   error=0.083333\n",
      "epoch 122/500   error=0.083333\n",
      "epoch 123/500   error=0.000000\n",
      "epoch 124/500   error=0.083333\n",
      "epoch 125/500   error=0.083333\n",
      "epoch 126/500   error=0.000000\n",
      "epoch 127/500   error=0.000000\n",
      "epoch 128/500   error=0.000000\n",
      "epoch 129/500   error=0.000000\n",
      "epoch 130/500   error=0.333333\n",
      "epoch 131/500   error=0.000000\n",
      "epoch 132/500   error=0.000000\n",
      "epoch 133/500   error=0.166667\n",
      "epoch 134/500   error=0.083333\n",
      "epoch 135/500   error=0.083333\n",
      "epoch 136/500   error=0.000000\n",
      "epoch 137/500   error=0.000000\n",
      "epoch 138/500   error=0.166667\n",
      "epoch 139/500   error=0.083333\n",
      "epoch 140/500   error=0.083333\n",
      "epoch 141/500   error=0.083333\n",
      "epoch 142/500   error=0.000000\n",
      "epoch 143/500   error=0.083333\n",
      "epoch 144/500   error=0.000000\n",
      "epoch 145/500   error=0.000000\n",
      "epoch 146/500   error=0.083333\n",
      "epoch 147/500   error=0.166667\n",
      "epoch 148/500   error=0.166667\n",
      "epoch 149/500   error=0.083333\n",
      "epoch 150/500   error=0.000000\n",
      "epoch 151/500   error=0.000000\n",
      "epoch 152/500   error=0.000000\n",
      "epoch 153/500   error=0.000000\n",
      "epoch 154/500   error=0.000000\n",
      "epoch 155/500   error=0.000000\n",
      "epoch 156/500   error=0.166667\n",
      "epoch 157/500   error=0.000000\n",
      "epoch 158/500   error=0.083333\n",
      "epoch 159/500   error=0.000000\n",
      "epoch 160/500   error=0.000000\n",
      "epoch 161/500   error=0.000000\n",
      "epoch 162/500   error=0.083333\n",
      "epoch 163/500   error=0.083333\n",
      "epoch 164/500   error=0.000000\n",
      "epoch 165/500   error=0.083333\n",
      "epoch 166/500   error=0.166667\n",
      "epoch 167/500   error=0.000000\n",
      "epoch 168/500   error=0.000000\n",
      "epoch 169/500   error=0.000000\n",
      "epoch 170/500   error=0.083333\n",
      "epoch 171/500   error=0.083333\n",
      "epoch 172/500   error=0.000000\n",
      "epoch 173/500   error=0.000000\n",
      "epoch 174/500   error=0.000000\n",
      "epoch 175/500   error=0.083333\n",
      "epoch 176/500   error=0.083333\n",
      "epoch 177/500   error=0.000000\n",
      "epoch 178/500   error=0.000000\n",
      "epoch 179/500   error=0.000000\n",
      "epoch 180/500   error=0.000000\n",
      "epoch 181/500   error=0.000000\n",
      "epoch 182/500   error=0.083333\n",
      "epoch 183/500   error=0.083333\n",
      "epoch 184/500   error=0.000000\n",
      "epoch 185/500   error=0.083333\n",
      "epoch 186/500   error=0.000000\n",
      "epoch 187/500   error=0.000000\n",
      "epoch 188/500   error=0.000000\n",
      "epoch 189/500   error=0.000000\n",
      "epoch 190/500   error=0.000000\n",
      "epoch 191/500   error=0.166667\n",
      "epoch 192/500   error=0.083333\n",
      "epoch 193/500   error=0.000000\n",
      "epoch 194/500   error=0.083333\n",
      "epoch 195/500   error=0.000000\n",
      "epoch 196/500   error=0.166667\n",
      "epoch 197/500   error=0.000000\n",
      "epoch 198/500   error=0.083333\n",
      "epoch 199/500   error=0.000000\n",
      "epoch 200/500   error=0.166667\n",
      "epoch 201/500   error=0.083333\n",
      "epoch 202/500   error=0.000000\n",
      "epoch 203/500   error=0.000000\n",
      "epoch 204/500   error=0.000000\n",
      "epoch 205/500   error=0.083333\n",
      "epoch 206/500   error=0.083333\n",
      "epoch 207/500   error=0.000000\n",
      "epoch 208/500   error=0.000000\n",
      "epoch 209/500   error=0.000000\n",
      "epoch 210/500   error=0.166667\n",
      "epoch 211/500   error=0.083333\n",
      "epoch 212/500   error=0.000000\n",
      "epoch 213/500   error=0.000000\n",
      "epoch 214/500   error=0.000000\n",
      "epoch 215/500   error=0.083333\n",
      "epoch 216/500   error=0.166667\n",
      "epoch 217/500   error=0.000000\n",
      "epoch 218/500   error=0.083333\n",
      "epoch 219/500   error=0.166667\n",
      "epoch 220/500   error=0.083333\n",
      "epoch 221/500   error=0.083333\n",
      "epoch 222/500   error=0.083333\n",
      "epoch 223/500   error=0.083333\n",
      "epoch 224/500   error=0.250000\n",
      "epoch 225/500   error=0.083333\n",
      "epoch 226/500   error=0.000000\n",
      "epoch 227/500   error=0.166667\n",
      "epoch 228/500   error=0.083333\n",
      "epoch 229/500   error=0.000000\n",
      "epoch 230/500   error=0.000000\n",
      "epoch 231/500   error=0.000000\n",
      "epoch 232/500   error=0.166667\n",
      "epoch 233/500   error=0.083333\n",
      "epoch 234/500   error=0.000000\n",
      "epoch 235/500   error=0.000000\n",
      "epoch 236/500   error=0.083333\n",
      "epoch 237/500   error=0.083333\n",
      "epoch 238/500   error=0.000000\n",
      "epoch 239/500   error=0.000000\n",
      "epoch 240/500   error=0.000000\n",
      "epoch 241/500   error=0.083333\n",
      "epoch 242/500   error=0.000000\n",
      "epoch 243/500   error=0.083333\n",
      "epoch 244/500   error=0.000000\n",
      "epoch 245/500   error=0.083333\n",
      "epoch 246/500   error=0.000000\n",
      "epoch 247/500   error=0.000000\n",
      "epoch 248/500   error=0.000000\n",
      "epoch 249/500   error=0.000000\n",
      "epoch 250/500   error=0.000000\n",
      "epoch 251/500   error=0.166667\n",
      "epoch 252/500   error=0.000000\n",
      "epoch 253/500   error=0.083333\n",
      "epoch 254/500   error=0.000000\n",
      "epoch 255/500   error=0.000000\n",
      "epoch 256/500   error=0.083333\n",
      "epoch 257/500   error=0.083333\n",
      "epoch 258/500   error=0.083333\n",
      "epoch 259/500   error=0.083333\n",
      "epoch 260/500   error=0.083333\n",
      "epoch 261/500   error=0.083333\n",
      "epoch 262/500   error=0.000000\n",
      "epoch 263/500   error=0.000000\n",
      "epoch 264/500   error=0.000000\n",
      "epoch 265/500   error=0.000000\n",
      "epoch 266/500   error=0.000000\n",
      "epoch 267/500   error=0.250000\n",
      "epoch 268/500   error=0.166667\n",
      "epoch 269/500   error=0.083333\n",
      "epoch 270/500   error=0.000000\n",
      "epoch 271/500   error=0.000000\n",
      "epoch 272/500   error=0.083333\n",
      "epoch 273/500   error=0.000000\n",
      "epoch 274/500   error=0.083333\n",
      "epoch 275/500   error=0.083333\n",
      "epoch 276/500   error=0.250000\n",
      "epoch 277/500   error=0.000000\n",
      "epoch 278/500   error=0.000000\n",
      "epoch 279/500   error=0.000000\n",
      "epoch 280/500   error=0.083333\n",
      "epoch 281/500   error=0.166667\n",
      "epoch 282/500   error=0.083333\n",
      "epoch 283/500   error=0.083333\n",
      "epoch 284/500   error=0.000000\n",
      "epoch 285/500   error=0.083333\n",
      "epoch 286/500   error=0.166667\n",
      "epoch 287/500   error=0.166667\n",
      "epoch 288/500   error=0.083333\n",
      "epoch 289/500   error=0.083333\n",
      "epoch 290/500   error=0.083333\n",
      "epoch 291/500   error=0.166667\n",
      "epoch 292/500   error=0.000000\n",
      "epoch 293/500   error=0.166667\n",
      "epoch 294/500   error=0.166667\n",
      "epoch 295/500   error=0.000000\n",
      "epoch 296/500   error=0.083333\n",
      "epoch 297/500   error=0.083333\n",
      "epoch 298/500   error=0.000000\n",
      "epoch 299/500   error=0.000000\n",
      "epoch 300/500   error=0.083333\n",
      "epoch 301/500   error=0.083333\n",
      "epoch 302/500   error=0.166667\n",
      "epoch 303/500   error=0.000000\n",
      "epoch 304/500   error=0.000000\n",
      "epoch 305/500   error=0.166667\n",
      "epoch 306/500   error=0.166667\n",
      "epoch 307/500   error=0.000000\n",
      "epoch 308/500   error=0.000000\n",
      "epoch 309/500   error=0.000000\n",
      "epoch 310/500   error=0.000000\n",
      "epoch 311/500   error=0.000000\n",
      "epoch 312/500   error=0.083333\n",
      "epoch 313/500   error=0.166667\n",
      "epoch 314/500   error=0.000000\n",
      "epoch 315/500   error=0.000000\n",
      "epoch 316/500   error=0.000000\n",
      "epoch 317/500   error=0.000000\n",
      "epoch 318/500   error=0.083333\n",
      "epoch 319/500   error=0.000000\n",
      "epoch 320/500   error=0.000000\n",
      "epoch 321/500   error=0.083333\n",
      "epoch 322/500   error=0.000000\n",
      "epoch 323/500   error=0.000000\n",
      "epoch 324/500   error=0.083333\n",
      "epoch 325/500   error=0.000000\n",
      "epoch 326/500   error=0.000000\n",
      "epoch 327/500   error=0.000000\n",
      "epoch 328/500   error=0.000000\n",
      "epoch 329/500   error=0.000000\n",
      "epoch 330/500   error=0.083333\n",
      "epoch 331/500   error=0.083333\n",
      "epoch 332/500   error=0.000000\n",
      "epoch 333/500   error=0.083333\n",
      "epoch 334/500   error=0.083333\n",
      "epoch 335/500   error=0.000000\n",
      "epoch 336/500   error=0.000000\n",
      "epoch 337/500   error=0.000000\n",
      "epoch 338/500   error=0.083333\n",
      "epoch 339/500   error=0.000000\n",
      "epoch 340/500   error=0.000000\n",
      "epoch 341/500   error=0.000000\n",
      "epoch 342/500   error=0.083333\n",
      "epoch 343/500   error=0.000000\n",
      "epoch 344/500   error=0.083333\n",
      "epoch 345/500   error=0.083333\n",
      "epoch 346/500   error=0.000000\n",
      "epoch 347/500   error=0.000000\n",
      "epoch 348/500   error=0.083333\n",
      "epoch 349/500   error=0.000000\n",
      "epoch 350/500   error=0.000000\n",
      "epoch 351/500   error=0.083333\n",
      "epoch 352/500   error=0.000000\n",
      "epoch 353/500   error=0.083333\n",
      "epoch 354/500   error=0.166667\n",
      "epoch 355/500   error=0.000000\n",
      "epoch 356/500   error=0.000000\n",
      "epoch 357/500   error=0.083333\n",
      "epoch 358/500   error=0.083333\n",
      "epoch 359/500   error=0.000000\n",
      "epoch 360/500   error=0.083333\n",
      "epoch 361/500   error=0.083333\n",
      "epoch 362/500   error=0.000000\n",
      "epoch 363/500   error=0.000000\n",
      "epoch 364/500   error=0.000000\n",
      "epoch 365/500   error=0.000000\n",
      "epoch 366/500   error=0.000000\n",
      "epoch 367/500   error=0.000000\n",
      "epoch 368/500   error=0.000000\n",
      "epoch 369/500   error=0.000000\n",
      "epoch 370/500   error=0.083333\n",
      "epoch 371/500   error=0.083333\n",
      "epoch 372/500   error=0.000000\n",
      "epoch 373/500   error=0.000000\n",
      "epoch 374/500   error=0.000000\n",
      "epoch 375/500   error=0.000000\n",
      "epoch 376/500   error=0.166667\n",
      "epoch 377/500   error=0.000000\n",
      "epoch 378/500   error=0.000000\n",
      "epoch 379/500   error=0.000000\n",
      "epoch 380/500   error=0.000000\n",
      "epoch 381/500   error=0.000000\n",
      "epoch 382/500   error=0.083333\n",
      "epoch 383/500   error=0.000000\n",
      "epoch 384/500   error=0.000000\n",
      "epoch 385/500   error=0.000000\n",
      "epoch 386/500   error=0.083333\n",
      "epoch 387/500   error=0.000000\n",
      "epoch 388/500   error=0.000000\n",
      "epoch 389/500   error=0.000000\n",
      "epoch 390/500   error=0.083333\n",
      "epoch 391/500   error=0.083333\n",
      "epoch 392/500   error=0.000000\n",
      "epoch 393/500   error=0.166667\n",
      "epoch 394/500   error=0.000000\n",
      "epoch 395/500   error=0.166667\n",
      "epoch 396/500   error=0.000000\n",
      "epoch 397/500   error=0.000000\n",
      "epoch 398/500   error=0.000000\n",
      "epoch 399/500   error=0.083333\n",
      "epoch 400/500   error=0.000000\n",
      "epoch 401/500   error=0.083333\n",
      "epoch 402/500   error=0.000000\n",
      "epoch 403/500   error=0.000000\n",
      "epoch 404/500   error=0.000000\n",
      "epoch 405/500   error=0.083333\n",
      "epoch 406/500   error=0.083333\n",
      "epoch 407/500   error=0.083333\n",
      "epoch 408/500   error=0.000000\n",
      "epoch 409/500   error=0.000000\n",
      "epoch 410/500   error=0.333333\n",
      "epoch 411/500   error=0.000000\n",
      "epoch 412/500   error=0.000000\n",
      "epoch 413/500   error=0.166667\n",
      "epoch 414/500   error=0.083333\n",
      "epoch 415/500   error=0.083333\n",
      "epoch 416/500   error=0.000000\n",
      "epoch 417/500   error=0.083333\n",
      "epoch 418/500   error=0.083333\n",
      "epoch 419/500   error=0.000000\n",
      "epoch 420/500   error=0.083333\n",
      "epoch 421/500   error=0.166667\n",
      "epoch 422/500   error=0.000000\n",
      "epoch 423/500   error=0.083333\n",
      "epoch 424/500   error=0.083333\n",
      "epoch 425/500   error=0.000000\n",
      "epoch 426/500   error=0.000000\n",
      "epoch 427/500   error=0.083333\n",
      "epoch 428/500   error=0.000000\n",
      "epoch 429/500   error=0.083333\n",
      "epoch 430/500   error=0.083333\n",
      "epoch 431/500   error=0.000000\n",
      "epoch 432/500   error=0.000000\n",
      "epoch 433/500   error=0.083333\n",
      "epoch 434/500   error=0.083333\n",
      "epoch 435/500   error=0.000000\n",
      "epoch 436/500   error=0.166667\n",
      "epoch 437/500   error=0.000000\n",
      "epoch 438/500   error=0.000000\n",
      "epoch 439/500   error=0.000000\n",
      "epoch 440/500   error=0.000000\n",
      "epoch 441/500   error=0.000000\n",
      "epoch 442/500   error=0.000000\n",
      "epoch 443/500   error=0.166667\n",
      "epoch 444/500   error=0.000000\n",
      "epoch 445/500   error=0.000000\n",
      "epoch 446/500   error=0.083333\n",
      "epoch 447/500   error=0.000000\n",
      "epoch 448/500   error=0.000000\n",
      "epoch 449/500   error=0.000000\n",
      "epoch 450/500   error=0.083333\n",
      "epoch 451/500   error=0.083333\n",
      "epoch 452/500   error=0.000000\n",
      "epoch 453/500   error=0.083333\n",
      "epoch 454/500   error=0.166667\n",
      "epoch 455/500   error=0.000000\n",
      "epoch 456/500   error=0.000000\n",
      "epoch 457/500   error=0.166667\n",
      "epoch 458/500   error=0.166667\n",
      "epoch 459/500   error=0.000000\n",
      "epoch 460/500   error=0.000000\n",
      "epoch 461/500   error=0.083333\n",
      "epoch 462/500   error=0.083333\n",
      "epoch 463/500   error=0.083333\n",
      "epoch 464/500   error=0.000000\n",
      "epoch 465/500   error=0.083333\n",
      "epoch 466/500   error=0.000000\n",
      "epoch 467/500   error=0.000000\n",
      "epoch 468/500   error=0.083333\n",
      "epoch 469/500   error=0.000000\n",
      "epoch 470/500   error=0.000000\n",
      "epoch 471/500   error=0.083333\n",
      "epoch 472/500   error=0.000000\n",
      "epoch 473/500   error=0.000000\n",
      "epoch 474/500   error=0.250000\n",
      "epoch 475/500   error=0.083333\n",
      "epoch 476/500   error=0.000000\n",
      "epoch 477/500   error=0.083333\n",
      "epoch 478/500   error=0.083333\n",
      "epoch 479/500   error=0.000000\n",
      "epoch 480/500   error=0.083333\n",
      "epoch 481/500   error=0.000000\n",
      "epoch 482/500   error=0.166667\n",
      "epoch 483/500   error=0.000000\n",
      "epoch 484/500   error=0.166667\n",
      "epoch 485/500   error=0.000000\n",
      "epoch 486/500   error=0.000000\n",
      "epoch 487/500   error=0.250000\n",
      "epoch 488/500   error=0.000000\n",
      "epoch 489/500   error=0.000000\n",
      "epoch 490/500   error=0.083333\n",
      "epoch 491/500   error=0.083333\n",
      "epoch 492/500   error=0.000000\n",
      "epoch 493/500   error=0.000000\n",
      "epoch 494/500   error=0.000000\n",
      "epoch 495/500   error=0.083333\n",
      "epoch 496/500   error=0.083333\n",
      "epoch 497/500   error=0.000000\n",
      "epoch 498/500   error=0.000000\n",
      "epoch 499/500   error=0.000000\n",
      "epoch 500/500   error=0.000000\n",
      "[array([[0.0000000e+00, 0.0000000e+00, 6.9388939e-18]]), array([[1., 1., 1.]]), array([[1., 1., 1.]]), array([[0.00000000e+00, 3.44642835e-20, 0.00000000e+00]])]\n"
     ]
    }
   ],
   "source": [
    "x_train = np.array([[[0,0]], [[0,1]], [[1,0]], [[1,1]]])\n",
    "y_train = np.array([[[0]], [[1]], [[1]], [[0]]])\n",
    "np.random.seed(10)\n",
    "net = Network()\n",
    "net.add(FCLayer(2, 10))\n",
    "net.add(ActivationLayer(relu, relu_prime))\n",
    "net.add(FCLayer(10, 3))\n",
    "net.add(ActivationLayer(relu, relu_prime))\n",
    "net.add(DropoutLayer(p=0.1))\n",
    "net.use(mse, mse_prime)\n",
    "net.fit(x_train, y_train, epochs=500, learning_rate=0.1)\n",
    "out = net.predict(x_train)\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 19\u001b[0m\n\u001b[0;32m     17\u001b[0m net\u001b[38;5;241m.\u001b[39madd(ActivationLayer(relu, relu_prime))\n\u001b[0;32m     18\u001b[0m net\u001b[38;5;241m.\u001b[39muse(mse, mse_prime)\n\u001b[1;32m---> 19\u001b[0m \u001b[43mnet\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m20\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlearning_rate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     20\u001b[0m out \u001b[38;5;241m=\u001b[39m net\u001b[38;5;241m.\u001b[39mpredict(x_test[\u001b[38;5;241m0\u001b[39m:\u001b[38;5;241m10\u001b[39m])\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[1;32mIn[7], line 35\u001b[0m, in \u001b[0;36mNetwork.fit\u001b[1;34m(self, x_train, y_train, epochs, learning_rate)\u001b[0m\n\u001b[0;32m     33\u001b[0m     error \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloss_prime(y_train[j], output)\n\u001b[0;32m     34\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m layer \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mreversed\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayers):\n\u001b[1;32m---> 35\u001b[0m         error \u001b[38;5;241m=\u001b[39m layer\u001b[38;5;241m.\u001b[39mbackward_propagation(error, learning_rate)\n\u001b[0;32m     36\u001b[0m err \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m=\u001b[39m samples\n\u001b[0;32m     37\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mepoch \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m   error=\u001b[39m\u001b[38;5;132;01m%f\u001b[39;00m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m%\u001b[39m (i\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m, epochs, err))\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "x_train = x_train.reshape(x_train.shape[0], 1, 28*28)\n",
    "x_train = x_train.astype('float32')\n",
    "x_train /= 255\n",
    "y_train = to_categorical(y_train)\n",
    "x_test = x_test.reshape(x_test.shape[0], 1, 28*28)\n",
    "x_test = x_test.astype('float32')\n",
    "x_test /= 255\n",
    "y_test = to_categorical(y_test)\n",
    "np.random.seed(10)\n",
    "net = Network()\n",
    "net.add(FCLayer(28*28, 100))\n",
    "net.add(ActivationLayer(relu, relu_prime))\n",
    "net.add(FCLayer(100, 50))\n",
    "net.add(ActivationLayer(relu, relu_prime))\n",
    "net.add(FCLayer(50, 10))\n",
    "net.add(ActivationLayer(relu, relu_prime))\n",
    "net.use(mse, mse_prime)\n",
    "net.fit(x_train, y_train, epochs=20, learning_rate=0.1)\n",
    "out = net.predict(x_test[0:10])\n",
    "print(\"\\n\")\n",
    "print(\"predicted values : \")\n",
    "print(out, end=\"\\n\")\n",
    "print(\"true values : \")\n",
    "print(y_test[0:10])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
